<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <title>Notes | Saeran Vasanthakumar</title>
    <link rel="stylesheet" type="text/css" href="/static/screen.css" media="screen" />
    <meta name="author" content="Saeran Vasanthakumar">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            extensions: ["tex2jax.js"],
            jax: ["input/TeX", "output/HTML-CSS"],
            chtml: {
                displayAlign: 'left', // default for indentalign when set to 'auto'
                displayIndent: '0' // default for indentshift when set to 'auto'
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ['\(','\)'] ],
                displayMath: [ ['$$','$$'], ['\[','\]']],
                skipTags: ["script","noscript","style","textarea", "code", "img src"],
                processClass: 'content',
                processEscapes: true
            },
            "HTML-CSS": {
                availableFonts: ["TeX"]
            }
        });
    </script>
</head>

<body>
<span class="content">
<span class="nbk_title"><a href="/">Notes</a></span>
<span class="nbk_comment"></span>
<span class="nbk_comment">by Saeran Vasanthakumar</span>
<span class="_doc_sep">---</span>

<span class="nbk_directive"><i>24/06/23 - How to measure &#34;information&#34; in a shape</i></span>

<div class="skinny_math">
Some thoughts on how simulated sampling can be used to effectively encode and decode polygon geometry. 

In order to determine how likely two shapes are the same (fuzzy matching) we define the likelihood distribution as \(p(d|shp)\). Normalizing by base rate of data/shape occurence:

\(\begin{align} 
& p(d|shp) \cdot \frac{p(shp)}{\sum_i{p(shp_i) \cdot p(d|shp_i)}}
= \frac{p(d \wedge shp_a)}{p(d)} \\
\end{align} \)
where: 
\( \begin{align}
&d &&= \set{pt_1, pt_2, pt_3,...pt_n} \text{,  data} \\
&p(shp_i) &&= area \text{ %,  parameter} \\
\end{align} \)

The most intuitive way to think of the likelihood distribution is as the SDF (for unit circle at origin),

\( \begin{align}
p(pt|shp) &= N( \sqrt{ pt_x^2 + pt_y^2 }\text{,  } 1 ), \\ 
&= \frac{ exp[-rad / 2 ] }{ \sqrt(2 \pi) }\\ 
\end{align} \)

So as the pt gets further away from the radius, it exp decays to zero. We can then measure the entropy of point scatter,
\( \begin{align}
H(data) &= \sum_i{ p(pt_i|shp) log( 1 / p(pt_i|shp) ) } \\
&= \sum_i{ p(pt_i|shp) log( N ) } \\
\end{align} \)   

So that, if \(p(pt_i|shp)\) cuts across the boundary, it's low entropy, but if all points are scattered away from the boundary, there's no peak, and its high entropy. Thus - as they put it in information theory - boundaries contain the most information. 

Technically, corners are even better, since in a 2D probability distribution edge gaussians have highly correlated x, y data along the edge axis (or dominant eigenvector of the covariance matrix \(X^T X\)). However, generating a shape from corner points seems to require additional information, like an adjacency matrix, which adds inflexibility. 

So sampling from a model of polygon edges will allow you to derive a lot of polygon information for the least amount of sample draws. 

</div>

<!-- autoescape off to allow images. Debug why safe filter isn't working
     ref for indent: https://jinja.palletsprojects.com/en/master/templates/#indent -->
<body>
<span class="_doc_sep">---</span>
<span class="nbk_grey">email: saeranv @ gmail dot com</span>
<span class="nbk_grey">git: <a href="https://github.com/saeranv/" style="color:grey;">github.com/saeranv</a></span>
</body>

</span>
</body>

</html>